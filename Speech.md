# Great Deep Learning Tutorials & Resources for Speech Processing
A Great Collection of Deep Learning Tutorials and Repositories for Speech Processing

## General (Spoken Language Processing (Speech Processing)):  
- [Audio Classification](https://towardsdatascience.com/audio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89) [_Great_]  
- [Building a Dead Simple Word Recognition Engine Using Convnet](https://blog.manash.me/building-a-dead-simple-word-recognition-engine-using-convnet-in-keras-25e72c19c12b)  
- [Identifying the Genre of a Song with Neural Networks](https://medium.com/@navdeepsingh_2336/identifying-the-genre-of-a-song-with-neural-networks-851db89c42f0)  
- [Modelling audio signal using visual features](https://raghavgoyal14.github.io/2018/04/12/audio-via-vid-features.html)  
- [ESC-50: Dataset for Environmental Sound Classification](https://github.com/karolpiczak/ESC-50)  
- [Kaldi Speech Recognition Toolkit](https://github.com/kaldi-asr/kaldi)  
- [PyTorch-Kaldi](https://github.com/mravanelli/pytorch-kaldi)  
- [SpeechBrain - PyTorch-based Speech Toolkit](https://speechbrain.github.io/)  
- [How to start with Kaldi and Speech Recognition](https://towardsdatascience.com/how-to-start-with-kaldi-and-speech-recognition-a9b7670ffff6)  
- [A 2019 Guide to Speech Synthesis with Deep Learning](https://heartbeat.fritz.ai/a-2019-guide-to-speech-synthesis-with-deep-learning-630afcafb9dd)  
- [A 2019 Guide for Automatic Speech Recognition](https://heartbeat.fritz.ai/a-2019-guide-for-automatic-speech-recognition-f1e1129a141c)  
- [PyKaldi](https://github.com/pykaldi/pykaldi)  
- [WaveNet vocoder](https://github.com/r9y9/wavenet_vocoder)  
- [nnAudio - audio processing toolbox using PyTorch](https://github.com/KinWaiCheuk/nnAudio)  
- [Athena - open-source implementation of end-to-end speech processing engine](https://github.com/athena-team/athena/tree/simclr)   
- [Pydub - manipulate audio](https://github.com/jiaaro/pydub)  
- [pyAcoustics - analyzing acoustics from audio files](https://github.com/timmahrt/pyAcoustics)  
- [ESPnet: end-to-end speech processing toolkit](https://github.com/espnet/espnet)  
- [WeNet](https://github.com/wenet-e2e/wenet) [Great]  
- [WeNet Android App](https://github.com/wenet-e2e/wenet/tree/main/runtime/device/android/wenet)   
- [NeMo - toolkit for Conversational AI](https://github.com/NVIDIA/NeMo) [_Excellent_]  

## Text to Speech (TTS):
- [Glow-TTS](https://github.com/jaywalnut310/glow-tts)  
- [ForwardTacotron](https://github.com/as-ideas/ForwardTacotron)  
- [WaveRNN Vocoder + TTS](https://github.com/fatchord/WaveRNN)  
- [Deep Voice 3 PyTorch](https://github.com/r9y9/deepvoice3_pytorch)  
- [MelGAN - TTS - version1](https://github.com/descriptinc/melgan-neurips)  
- [MelGAN - TTS - version2](https://github.com/seungwonpark/melgan)  
- [FastSpeech - TTS - version1](https://github.com/xcmyz/FastSpeech)  
- [FastSpeech - TTS - version2](https://github.com/ming024/FastSpeech2)  
- [Mozilla - TTS](https://github.com/mozilla/TTS)  
- [YourTTS: Zero-Shot Multi-Speaker TTS](https://github.com/edresson/yourtts)  

## Automatic Speech Recognition (ASR) & Speech to Text (STT):
- [OpenSpeech](https://github.com/openspeech-team/openspeech) [Great]   
- [wav2letter++](https://github.com/facebookresearch/wav2letter)  
- [End-to-End ASR - PyTorch](https://github.com/Alexander-H-Liu/End-to-end-ASR-Pytorch)  
- [NeuralSP](https://github.com/hirofumi0810/neural_sp)  
- [Silero Speech-To-Text Models - PyTorch Hub](https://pytorch.org/hub/snakers4_silero-models_stt/)  
- [Silero Models - GitHub](https://github.com/snakers4/silero-models)  
- [Hugging Faceâ€™s Wav2Vec2 & its First ASR Model](https://www.analyticsvidhya.com/blog/2021/02/hugging-face-introduces-the-first-automatic-speech-recognition-model-wav2vec2/)  
- [Hugging Face - wav2vec2](https://huggingface.co/transformers/model_doc/wav2vec2.html)  
- [PyTorch Wav2Vec](https://github.com/pytorch/fairseq/tree/master/examples/wav2vec/unsupervised)   
- [Self-training and pre-training, understanding the wav2vec series](https://maelfabien.github.io/machinelearning/wav2vec/#)   
- [Conformer](https://github.com/sooftware/conformer)  
- [Keras based Training a CTC-based model for ASR](https://keras.io/examples/audio/ctc_asr/)   
- [fairseq](https://github.com/pytorch/fairseq)   
- [TensorFlowASR](https://github.com/TensorSpeech/TensorFlowASR) [Good]    
- [BigSSL: Large-Scale Semi-Supervised Learning for Automatic Speech Recognition](https://arxiv.org/pdf/2109.13226.pdf)  

### Persian ASR Repos:
- [wav2vec2-fa](https://github.com/Hamtech-ai/wav2vec2-fa)  
- [Shenasa-ai Speech2Text](https://github.com/shenasa-ai/speech2text)  

## G2P (Grapheme2Phoneme):
- [English Grapheme To Phoneme (G2P) Conversion](https://github.com/Kyubyong/g2p)   
- [Phonemizer: Simple text to phones converter for multiple languages](https://github.com/bootphon/phonemizer)   
- [Epitran: tool for transcribing orthographic text as IPA](https://github.com/dmort27/epitran)   
- [PersianG2P](https://github.com/PasaOpasen/PersianG2P)  
- [Persian_G2P - link2](https://github.com/AzamRabiee/Persian_G2P)   

## Source Separation:
- [Deezer source separation library](https://github.com/deezer/spleeter) [Great]   

## Sound & Audio Classification:
- [Soxan: Wav2Vec2 for speech recognition](https://github.com/m3hrdadfi/soxan)  

## Voice Activity Detection:
- [Voice Activity Detection: Identifying whether someone is speaking or not](https://maelfabien.github.io/project/Speech_proj/#) [**Great**]    

## Annotation Tools:
- [audino: open source audio annotation tool](https://github.com/midas-research/audino)   

## Some ASR Datasets:
- [Peoples Speech](https://mlcommons.org/en/peoples-speech/)  
- [Multilingual Spoken Words](https://mlcommons.org/en/multilingual-spoken-words/)  
  
